{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données depuis les fichiers CSV\n",
    "prenom_sex = pd.read_csv('/home/onyxia/work/firstname_with_sex.csv', sep = \";\")\n",
    "transcription_sex_df = pd.read_csv('/home/onyxia/work/transcriptions_with_sex.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/tmp/ipykernel_26587/167063245.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle: 0.7069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       homme       0.80      0.49      0.60       107\n",
      "       femme       0.67      0.90      0.77       125\n",
      "\n",
      "    accuracy                           0.71       232\n",
      "   macro avg       0.74      0.69      0.69       232\n",
      "weighted avg       0.73      0.71      0.69       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Évaluation du modèle: camembert/camembert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/tmp/ipykernel_26587/167063245.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle: 0.4612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       homme       0.46      0.99      0.63       107\n",
      "       femme       0.50      0.01      0.02       125\n",
      "\n",
      "    accuracy                           0.46       232\n",
      "   macro avg       0.48      0.50      0.32       232\n",
      "weighted avg       0.48      0.46      0.30       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Évaluation du modèle: flaubert/flaubert_large_cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_large_cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/tmp/ipykernel_26587/167063245.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle: 0.4914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       homme       0.47      0.77      0.58       107\n",
      "       femme       0.56      0.26      0.35       125\n",
      "\n",
      "    accuracy                           0.49       232\n",
      "   macro avg       0.51      0.51      0.47       232\n",
      "weighted avg       0.52      0.49      0.46       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Évaluation du modèle: facebook/bart-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/tmp/ipykernel_26587/167063245.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle: 0.4655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       homme       0.46      1.00      0.63       107\n",
      "       femme       1.00      0.01      0.02       125\n",
      "\n",
      "    accuracy                           0.47       232\n",
      "   macro avg       0.73      0.50      0.32       232\n",
      "weighted avg       0.75      0.47      0.30       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Évaluation du modèle: camembert/camembert-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7042411f08a74321b52275cb6447c485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8132db0d7f411f856672c106246575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'roberta.embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c459e382fc2a4907816937dee7712957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle: 0.4784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       homme       0.41      0.30      0.35       107\n",
      "       femme       0.51      0.63      0.57       125\n",
      "\n",
      "    accuracy                           0.48       232\n",
      "   macro avg       0.46      0.47      0.46       232\n",
      "weighted avg       0.47      0.48      0.46       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26587/167063245.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Liste des modèles BERT à tester\n",
    "models_to_test = [\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"camembert/camembert-base\",\n",
    "    \"flaubert/flaubert_large_cased\",\n",
    "    \"facebook/bart-large\",\n",
    "    \"camembert/camembert-large\"\n",
    "]\n",
    "\n",
    "# Labels pour la classification\n",
    "labels = [\"masculin\", \"feminin\"]\n",
    "\n",
    "# Mapping des labels prédits vers les labels originaux\n",
    "label_mapping = {\n",
    "    'masculin': 'homme',\n",
    "    'feminin': 'femme'\n",
    "}\n",
    "\n",
    "# Itérer sur chaque modèle\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Évaluation du modèle: {model_name}\")\n",
    "\n",
    "    # Initialiser le pipeline de classification zero-shot\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "    # Classifier les textes\n",
    "    predicted_sexes = []\n",
    "    for text in transcription_sex_df['prediction']:\n",
    "        result = classifier(text, candidate_labels=labels, hypothesis_template=\"Cette personne est de sexe {}.\")\n",
    "        predicted_label = result['labels'][0]\n",
    "        predicted_sexes.append(predicted_label)\n",
    "\n",
    "    # Ajouter les résultats au DataFrame\n",
    "    transcription_sex_df['predicted_sex'] = predicted_sexes\n",
    "\n",
    "    # Filtrer pour exclure les entrées 'ambigu'\n",
    "    transcription_sex_filtered = transcription_sex_df[transcription_sex_df['sex'] != 'ambigu']\n",
    "\n",
    "    # Appliquer le mapping des labels prédits\n",
    "    transcription_sex_filtered['predicted_sex_mapped'] = transcription_sex_filtered['predicted_sex'].map(label_mapping)\n",
    "\n",
    "    # Calculer la précision\n",
    "    accuracy = accuracy_score(transcription_sex_filtered['sex'], transcription_sex_filtered['predicted_sex_mapped'])\n",
    "\n",
    "    # Afficher les résultats\n",
    "    print(f\"Précision du modèle: {accuracy:.4f}\")\n",
    "    print(classification_report(transcription_sex_filtered['sex'], transcription_sex_filtered['predicted_sex_mapped'], target_names=list(label_mapping.values())))\n",
    "\n",
    "    # Pour la lisibilité des résultats\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenom_sex['total'] = prenom_sex['male'] + prenom_sex['female']\n",
    "\n",
    "# Calculer la probabilité pour chaque prenom d'être masculin ou féminin\n",
    "prenom_sex['prob_male'] = prenom_sex['male'] / prenom_sex['total']\n",
    "prenom_sex['prob_female'] = prenom_sex['female'] / prenom_sex['total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex_prenom = r\"prénom:\\s*([\\wéèêëîïôöûüàâäÉÈÊËÎÏÔÖÛÜÀÂÄ'-]+(?:\\s+[\\wéèêëîïôöûüàâäÉÈÊËÎÏÔÖÛÜÀÂÄ'-]+)*)(?=\\s+date|\\s+lieux| )\"\n",
    "transcription_sex_df['prenom'] = transcription_sex_df['prediction'].apply(lambda x: re.search(regex_prenom, x).group(1) if re.search(regex_prenom, x) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_regex = transcription_sex_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import gender_guesser.detector as gender\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Initialise le detector\n",
    "detector = gender.Detector()\n",
    "\n",
    "# Parcours de chaque prenom dans transcription_sex_df\n",
    "for index, row in transcription_regex.iterrows():\n",
    "    prenom = row['prenom']\n",
    "    \n",
    "    # Recherche du prenom dans prenom_sex\n",
    "    if prenom in prenom_sex['firstname'].values:\n",
    "        # Si le prenom est trouvé dans prenom_sex, utilisez la probabilité associée pour déterminer le sexe\n",
    "        probabilité = prenom_sex.loc[prenom_sex['firstname'] == prenom, 'prob_male'].values[0]\n",
    "        predicted_sex = 'femme' if probabilité < 0.5 else 'homme'\n",
    "    else:\n",
    "        # Si le prenom n'est pas trouvé dans prenom_sex, utilisez gender_guesser.detector\n",
    "        genre = detector.get_gender(prenom)\n",
    "        if genre == 'male':\n",
    "            predicted_sex = 'homme'\n",
    "        elif genre == 'female':\n",
    "            predicted_sex = 'femme'\n",
    "        else:\n",
    "            # Si le genre n'est pas déterminé par le detector, cherchez le prenom le plus proche dans prenom_sex\n",
    "            prenom_proche = process.extractOne(prenom, prenom_sex['firstname'])[0]\n",
    "            probabilité = prenom_sex.loc[prenom_sex['firstname'] == prenom_proche, 'prob_male'].values[0]\n",
    "            predicted_sex = 'femme' if probabilité < 0.5 else 'homme'\n",
    "    # Attribuer le sexe au prenom dans transcription_sex_df\n",
    "    transcription_regex.at[index, 'predicted_sex'] = predicted_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_line</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sex</th>\n",
       "      <th>predicted_sex</th>\n",
       "      <th>prenom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>f6ed3c4c-198f-4e05-b19e-d8cdcd2f8f2c</td>\n",
       "      <td>surname: Châtel firstname: Jeanne occupation: ...</td>\n",
       "      <td>nom: Chatel prénom: Jeanne date_naissance: 52 ...</td>\n",
       "      <td>femme</td>\n",
       "      <td>femme</td>\n",
       "      <td>Jeanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>e1e6fb82-6417-4dcf-8eaa-7d5a5e9f6551</td>\n",
       "      <td>surname: Roumeau firstname: Claude occupation:...</td>\n",
       "      <td>nom: Roumeau prénom: Vaude date_naissance: 180...</td>\n",
       "      <td>ambigu</td>\n",
       "      <td>femme</td>\n",
       "      <td>Vaude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>130835c5-43f4-4af8-8f20-2a1c26845994</td>\n",
       "      <td>surname: Grillé firstname: Antoine occupation:...</td>\n",
       "      <td>nom: Grille prénom: antoine date_naissance: 46...</td>\n",
       "      <td>homme</td>\n",
       "      <td>homme</td>\n",
       "      <td>antoine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a0aa0b6a-0226-4769-b156-72d2f6afcd36</td>\n",
       "      <td>surname: Raduron firstname: Anne link: Sa femm...</td>\n",
       "      <td>nom: Raduron prénom: Anne date_naissance: 53 l...</td>\n",
       "      <td>femme</td>\n",
       "      <td>femme</td>\n",
       "      <td>Anne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>46357142-d514-454e-a6b2-f2d57a9d3cc7</td>\n",
       "      <td>surname: Brun firstname: Jacques occupation: g...</td>\n",
       "      <td>nom: Brun prénom: Jregues date_naissance: 5 0n...</td>\n",
       "      <td>homme</td>\n",
       "      <td>homme</td>\n",
       "      <td>Jregues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            subject_line  \\\n",
       "37  f6ed3c4c-198f-4e05-b19e-d8cdcd2f8f2c   \n",
       "94  e1e6fb82-6417-4dcf-8eaa-7d5a5e9f6551   \n",
       "29  130835c5-43f4-4af8-8f20-2a1c26845994   \n",
       "12  a0aa0b6a-0226-4769-b156-72d2f6afcd36   \n",
       "82  46357142-d514-454e-a6b2-f2d57a9d3cc7   \n",
       "\n",
       "                                          groundtruth  \\\n",
       "37  surname: Châtel firstname: Jeanne occupation: ...   \n",
       "94  surname: Roumeau firstname: Claude occupation:...   \n",
       "29  surname: Grillé firstname: Antoine occupation:...   \n",
       "12  surname: Raduron firstname: Anne link: Sa femm...   \n",
       "82  surname: Brun firstname: Jacques occupation: g...   \n",
       "\n",
       "                                           prediction     sex predicted_sex  \\\n",
       "37  nom: Chatel prénom: Jeanne date_naissance: 52 ...   femme         femme   \n",
       "94  nom: Roumeau prénom: Vaude date_naissance: 180...  ambigu         femme   \n",
       "29  nom: Grille prénom: antoine date_naissance: 46...   homme         homme   \n",
       "12  nom: Raduron prénom: Anne date_naissance: 53 l...   femme         femme   \n",
       "82  nom: Brun prénom: Jregues date_naissance: 5 0n...   homme         homme   \n",
       "\n",
       "     prenom  \n",
       "37   Jeanne  \n",
       "94    Vaude  \n",
       "29  antoine  \n",
       "12     Anne  \n",
       "82  Jregues  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_regex.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entre predicted_sex et sex: 0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "transcription_regex_filt = transcription_regex[transcription_regex['sex'] != 'ambigu']\n",
    "\n",
    "accuracy_sex = (transcription_regex_filt['predicted_sex'] == transcription_regex_filt['sex']).mean()\n",
    "print(\"Accuracy entre predicted_sex et sex:\", accuracy_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_regex2 = transcription_sex_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_profession = r\"profession:\\s*([\\w\\s'-]+)(?=\\s+employeur|\\s+relation|\\s+date_naissance|\\s+lieux_naissance|$)\"\n",
    "regex_relation = r\"relation:\\s*([\\w\\s'-]+)(?=\\s+employeur|\\s+profession|\\s+date_naissance|\\s+lieux_naissance|$)\"\n",
    "\n",
    "transcription_regex2['profession'] = transcription_regex2['prediction'].apply(lambda x: re.search(regex_profession, x).group(1) if re.search(regex_profession, x) else '')\n",
    "transcription_regex2['relation'] = transcription_regex2['prediction'].apply(lambda x: re.search(regex_relation, x).group(1) if re.search(regex_relation, x) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Dictionnaire associant les indications de sexe à une lettre\n",
    "sexe_dict = {\n",
    "    'fille': 'F',\n",
    "    'femme': 'F',\n",
    "    'épouse': 'F',\n",
    "    'ep': 'F',\n",
    "    'ép': 'F',\n",
    "    'belle-mère': 'F',\n",
    "    'petite-fille': 'F',\n",
    "    'fils': 'M',\n",
    "    'frère' : 'M'\n",
    "    # Ajoutez d'autres indications de sexe et leur lettre correspondante ici\n",
    "}\n",
    "\n",
    "def extract_sex_from_relation(relation, sexe_dict):\n",
    "    # Recherche de correspondances exactes dans le dictionnaire\n",
    "    if relation.lower().strip() in sexe_dict:\n",
    "        return sexe_dict[relation.lower().strip()]\n",
    "    \n",
    "    # Recherche de correspondances approximatives dans le dictionnaire\n",
    "    for key, value in sexe_dict.items():\n",
    "        # Comparaison en utilisant le ratio de similarité de Levenshtein\n",
    "        if fuzz.ratio(relation.lower().strip(), key.lower()) > 80:  # Ajustez le seuil selon vos besoins\n",
    "            return value\n",
    "    \n",
    "    # Vérification de l'inclusion dans une phrase plus longue\n",
    "    words = relation.lower().strip().split()\n",
    "    \n",
    "    # Vérification de l'inclusion en tant que mot complet dans une phrase plus longue\n",
    "    for word in words:\n",
    "        for key, value in sexe_dict.items():\n",
    "            # Vérifiez si le mot correspond exactement à une clé dans le dictionnaire\n",
    "            if word == key.lower():\n",
    "                return value\n",
    "    \n",
    "    # Vérification du suffixe avec regex pour gérer les espaces et caractères non alphanumériques à la fin\n",
    "    #suffixes_feminins = ['ère', 'euse', 'ée', 'ice']\n",
    "    #for suffix in suffixes_feminins:\n",
    "     #   if re.search(suffix + r'\\W*$', relation.lower()):\n",
    "      #      return 'F'\n",
    "    \n",
    "    return ''\n",
    "\n",
    "# Appliquer la fonction à la colonne 'relation' pour créer la nouvelle colonne 'info_sex_relation'\n",
    "transcription_regex2['info_sex_relation'] = transcription_regex2['relation'].apply(lambda x: extract_sex_from_relation(x, sexe_dict))\n",
    "transcription_regex2['info_sex_profession'] = transcription_regex2['profession'].apply(lambda x: extract_sex_from_relation(x, sexe_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sex_columns(row):\n",
    "    # Si les deux colonnes sont 'M'\n",
    "    if row['info_sex_relation'] == 'M' and row['info_sex_profession'] == 'M':\n",
    "        return 'homme'\n",
    "    # Si les deux colonnes sont 'F'\n",
    "    elif row['info_sex_relation'] == 'F' and row['info_sex_profession'] == 'F':\n",
    "        return 'femme'\n",
    "    # Si l'une des colonnes est 'M' et l'autre est vide\n",
    "    elif row['info_sex_relation'] == 'M' or row['info_sex_profession'] == 'M':\n",
    "        return 'homme'\n",
    "    # Si l'une des colonnes est 'F' et l'autre est vide\n",
    "    elif row['info_sex_relation'] == 'F' or row['info_sex_profession'] == 'F':\n",
    "        return 'femme'\n",
    "    # Si les deux colonnes sont non vides mais différentes, ou si les deux sont vides\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Appliquer la fonction combine_sex_columns pour créer la colonne 'predicted_sex'\n",
    "transcription_regex2['predicted_sex'] = transcription_regex2.apply(combine_sex_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Initialise le detector\n",
    "detector = gender.Detector()\n",
    "\n",
    "# Supposons que prenom_sex est un DataFrame déjà défini avec les colonnes 'firstname' et 'prob_male'\n",
    "# Si ce n'est pas le cas, vous devez le définir ou le charger avant d'exécuter ce code.\n",
    "\n",
    "# Parcours de chaque ligne dans transcription_regex2 là où predicted_sex est None\n",
    "for index, row in transcription_regex2[transcription_regex2['predicted_sex'].isnull()].iterrows():\n",
    "    prenom = row['prenom']\n",
    "    \n",
    "    # Si le prénom est vide ou NaN, passez à l'entrée suivante\n",
    "    if pd.isnull(prenom):\n",
    "        continue\n",
    "    \n",
    "    # Recherche du prenom dans prenom_sex\n",
    "    if prenom in prenom_sex['firstname'].values:\n",
    "        probabilité = prenom_sex.loc[prenom_sex['firstname'] == prenom, 'prob_male'].values[0]\n",
    "        predicted_sex = 'femme' if probabilité < 0.5 else 'homme'\n",
    "    else:\n",
    "        # Utilisation de gender_guesser.detector\n",
    "        genre = detector.get_gender(prenom)\n",
    "        if genre == 'male':\n",
    "            predicted_sex = 'homme'\n",
    "        elif genre == 'female':\n",
    "            predicted_sex = 'femme'\n",
    "        else:\n",
    "            # Recherche du prénom le plus proche\n",
    "            prenom_proche = process.extractOne(prenom, prenom_sex['firstname'])[0]\n",
    "            probabilité = prenom_sex.loc[prenom_sex['firstname'] == prenom_proche, 'prob_male'].values[0]\n",
    "            predicted_sex = 'femme' if probabilité < 0.5 else 'homme'\n",
    "            \n",
    "    # Mettre à jour la valeur de 'predicted_sex' si elle est None\n",
    "    transcription_regex2.at[index, 'predicted_sex'] = predicted_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entre predicted_sex et sex: 0.9698275862068966\n"
     ]
    }
   ],
   "source": [
    "transcription_regex2_filt = transcription_regex2[transcription_regex2['sex'] != 'ambigu']\n",
    "\n",
    "accuracy_sex = (transcription_regex2_filt['predicted_sex'] == transcription_regex2_filt['sex']).mean()\n",
    "print(\"Accuracy entre predicted_sex et sex:\", accuracy_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_ml = transcription_sex_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_ml_filt = transcription_ml[transcription_ml['sex'] != 'ambigu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8405\n",
      "SVM Accuracy: 0.6940\n",
      "KNN Accuracy: 0.5388\n",
      "Decision Tree Accuracy: 0.8147\n",
      "Random Forest Accuracy: 0.8147\n",
      "Gradient Boosting Accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initialisation des modèles à tester\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000)),\n",
    "    (\"SVM\", SVC(probability=True)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Vectorisation des textes\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(transcription_ml_filt['prediction'])\n",
    "\n",
    "# Initialisation de la validation croisée Leave-One-Out\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Boucle pour tester chaque modèle\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)), # SVM, Logistic Regression bénéficient de la mise à l'échelle\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Évaluation du modèle\n",
    "    scores = cross_val_score(pipeline, X_vectorized, transcription_ml_filt['sex'], cv=loo, scoring='accuracy')\n",
    "    accuracy = np.mean(scores)\n",
    "    \n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_llm_filt = transcription_sex_df[transcription_sex_df['sex'] != 'ambigu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/mamba/lib/python3.11/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "Train loss 0.03213329310454226 accuracy 0.9870002795638804\n",
      "Val   loss 0.1490473486483097 accuracy 0.9583333333333333\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "Train loss 0.0065686846110760855 accuracy 0.9980430528375733\n",
      "Val   loss 0.17160173668526113 accuracy 0.9583333333333333\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "Train loss 0.003592518474468826 accuracy 0.9993010902991334\n",
      "Val   loss 0.0034892880357801914 accuracy 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Préparation des données\n",
    "df = transcription_llm_filt[['prediction', 'sex']].copy()  # Utilisez votre DataFrame original\n",
    "df['label'] = df['sex'].map({'homme': 0, 'femme': 1})\n",
    "\n",
    "# Séparation des données en ensemble d'entraînement et de test\n",
    "df_train, df_val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Fonction pour créer des phrases à partir de prenom_sex\n",
    "def create_sentence_from_prenom(row):\n",
    "    if row['prob_male'] > 0.5:\n",
    "        return f\"Le prénom {row['firstname']} est généralement porté par un homme.\", 0  # 0 pour homme\n",
    "    else:\n",
    "        return f\"Le prénom {row['firstname']} est généralement porté par une femme.\", 1  # 1 pour femme\n",
    "\n",
    "# Appliquer cette fonction à chaque ligne du DataFrame prenom_sex et l'ajouter à l'ensemble d'entraînement\n",
    "prenom_sentences_labels = [create_sentence_from_prenom(row) for _, row in prenom_sex.iterrows()]\n",
    "prenom_df = pd.DataFrame(prenom_sentences_labels, columns=['prediction', 'label'])\n",
    "df_train = pd.concat([df_train, prenom_df]).reset_index(drop=True)\n",
    "df_train['sex'] = df_train.apply(\n",
    "    lambda row: 'homme' if row['label'] == 0 else ('femme' if row['label'] == 1 else np.nan), axis=1\n",
    ")\n",
    "# Make sure the labels are integers\n",
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_val['label'] = df_val['label'].astype(int)\n",
    "\n",
    "# Classe personnalisée pour le dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Paramètres du tokenizer et du modèle\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "MAX_LEN = 100  # Ou la longueur maximale que vous voulez utiliser\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = TextDataset(df_train['prediction'].to_numpy(), df_train['label'].to_numpy(), tokenizer, MAX_LEN)\n",
    "val_dataset = TextDataset(df_val['prediction'].to_numpy(), df_val['label'].to_numpy(), tokenizer, MAX_LEN)\n",
    "\n",
    "# Création des DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Chargement du modèle BERT pré-entraîné\n",
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels=2)\n",
    "model = model.to(device)  # Envoyer le modèle sur le GPU si disponible\n",
    "\n",
    "# Paramètres d'entraînement\n",
    "EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Fonction pour l'évaluation\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val) \n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    # Sauvegarde du meilleur modèle\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
